{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) How would you define Machine Learning?\n",
    "Machine Learning is a field of Artificial Intelligence that uses algorithms to allow computers to learn from examples without being explicitly programmed. \n",
    "## 2) What are the differences between Supervised and Unsupervised Learning? Specify example 3 algorithms for each of these.\n",
    "Differences between Supervised and Unsupervised Learning: \n",
    "- data is labelled in supervised learning for the algorithm to learn from\n",
    "- data is unlabelled in unsupervised learning for the algorithm to learn from\n",
    "Supervised learning: classification, regression and decision trees\n",
    "Unsupervised learning: clustering, neural networks, KNN\n",
    "## 3) What are the test and validation set, and why would you want to use them?\n",
    "Test set: the sample of data used to provide an unbiased evaluation of a final model fit on the training dataset to be able to test the model performance\n",
    "Validation set: The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The evaluation becomes more biased as skill on the validation dataset is incorporated into the model configuration.\n",
    "## 4) What are the main preprocessing steps? Explain them in detail. Why we need to prepare our data?\n",
    "1. Identify and remove duplicate values to not give that particular data object an advantage or bias, when running machine learning algorithms.\n",
    "2. Identify if the data is balanced or unbalanced to conduct undersampling or over sampling.\n",
    "3. Identify missing values and either remove them or fill them with the mean or median.\n",
    "4. Identify outliers in the data using standard deviation and IQR calculations.\n",
    "5. Identify if feature scaling is necessary to standardize and/or normalize the data.\n",
    "6. Data binning, bucketing is a data pre-processing method used to minimize the effects of small observation errors (noisy data). The original data values are divided into small intervals known as bins and then they are replaced by a general value calculated for that bin.\n",
    "7. Feature extraction using PCA, ICA, LDA and t-SNE.\n",
    "8. Feature encoding is basically performing transformations on the data such that it can be easily accepted as input for machine learning algorithms while still retaining its original meaning.\n",
    "9. Split the data into train, test and validation sets to train the algorithm and evaluate its performance on the data.\n",
    "We need to prepare our data because raw data is always incomplete and cannot be sent through a model. \n",
    "\n",
    "## 5) How you can explore countionus and discrete variables?\n",
    "Continuous variables: using a probability density function\n",
    "Discrete variables: using a probability mass function\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
